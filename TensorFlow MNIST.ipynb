{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d412c6fe",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "The dataset is called MNIST and refers to handwritten digit recongnition.\n",
    "\n",
    "The dataset provides 70000 images (28x28 pixels) of handwritten digits (1 digit per image).\n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits, this is a classification problem with 10 classes. \n",
    "\n",
    "Goals is to build a neural network with 2 hidden layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091edc0",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ab19d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#pip install tensorflow_datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f885df4",
   "metadata": {},
   "source": [
    "## Disable Python warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74fe9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d856c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "930b5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 13:45:39.632011: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "#tfds.load loads a datasets\n",
    "#with_info = True will provide us with a tuple containing information about the version, features, number of samples\n",
    "#as_supervised = True will laod the dataset in a 2-tuple structure (input, target)\n",
    "mnist_dataset, mnist_info = tfds.load(name = \"mnist\", with_info = True, as_supervised = True)\n",
    "\n",
    "#extract the training and testing dataset with build references\n",
    "mnist_train, mnist_test = mnist_dataset[\"train\"], mnist_dataset[\"test\"]\n",
    "\n",
    "#TensorFlow has training and testing datasets but no validation sets, thus we need to split it on our own\n",
    "\n",
    "#defining the number of validation samples as a % of the train samples\n",
    "num_validation_samples = 0.1 * mnist_info.splits[\"train\"].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64) #convert to integer\n",
    "\n",
    "#store the number of test samples in variable\n",
    "num_test_samples = mnist_info.splits[\"test\"].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64) #convert to integer\n",
    "\n",
    "#define a function called scale; take an MNIST image and label\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32) #value make it as float\n",
    "    image /= 255. #divide each element by 255 as the possible values for the inputs are 0 to 255\n",
    "    return image, label\n",
    "\n",
    "#.map() allow us to apply custom transformation to a given dataset\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "#shuffle the data \n",
    "\n",
    "#set buffer size parameter for cases when dealing with enormous datasets\n",
    "#can't shuffle the whole dataset in one go becasue can't fit it all in memory\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "#.shuffle() method to shuffle\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "#.take() method to take many samples\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "#.skip() skip as many samples as there are in the validation dataset\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "#batch the data\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_test_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "#take next batch; also the only batch as we set as_supervized = True, only got 2-tuple structure \n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfb448",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Outline the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acdf96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "#define how the model will look like\n",
    "model = tf.keras.Sequential([\n",
    "                              #each observation is 28x28x1 pixels, therefore is tensor of rank 3\n",
    "                              #don't know CNNs yet, need to flatten the images; \n",
    "                              #use the Flatten method to converts multi-dimensional arrays into flattened one-dimensional arrays\n",
    "                              tf.keras.layers.Flatten(input_shape = (28, 28, 1)), #input layer\n",
    "                              #use the Dense method\n",
    "                              tf.keras.layers.Dense(hidden_layer_size, activation = \"relu\"), #1st hidden layer\n",
    "                              tf.keras.layers.Dense(hidden_layer_size, activation = \"relu\"), #2nd hidden layer\n",
    "                              #activate final layer with softmax\n",
    "                              tf.keras.layers.Dense(output_size, activation = \"softmax\") #output layer\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fc014",
   "metadata": {},
   "source": [
    "### Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86f1f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizer, loss and metrics\n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463d4ea",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e0b8e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "540/540 - 1s - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0295 - val_accuracy: 0.9902 - 672ms/epoch - 1ms/step\n",
      "Epoch 2/30\n",
      "540/540 - 1s - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0350 - val_accuracy: 0.9887 - 606ms/epoch - 1ms/step\n",
      "Epoch 3/30\n",
      "540/540 - 1s - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0206 - val_accuracy: 0.9938 - 621ms/epoch - 1ms/step\n",
      "Epoch 4/30\n",
      "540/540 - 1s - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0132 - val_accuracy: 0.9952 - 626ms/epoch - 1ms/step\n",
      "Epoch 5/30\n",
      "540/540 - 1s - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0177 - val_accuracy: 0.9940 - 594ms/epoch - 1ms/step\n",
      "Epoch 6/30\n",
      "540/540 - 1s - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0130 - val_accuracy: 0.9967 - 606ms/epoch - 1ms/step\n",
      "Epoch 7/30\n",
      "540/540 - 1s - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0133 - val_accuracy: 0.9955 - 630ms/epoch - 1ms/step\n",
      "Epoch 8/30\n",
      "540/540 - 1s - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0120 - val_accuracy: 0.9957 - 634ms/epoch - 1ms/step\n",
      "Epoch 9/30\n",
      "540/540 - 1s - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0188 - val_accuracy: 0.9943 - 606ms/epoch - 1ms/step\n",
      "Epoch 10/30\n",
      "540/540 - 1s - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0121 - val_accuracy: 0.9967 - 638ms/epoch - 1ms/step\n",
      "Epoch 11/30\n",
      "540/540 - 1s - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0122 - val_accuracy: 0.9952 - 693ms/epoch - 1ms/step\n",
      "Epoch 12/30\n",
      "540/540 - 1s - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0177 - val_accuracy: 0.9945 - 672ms/epoch - 1ms/step\n",
      "Epoch 13/30\n",
      "540/540 - 1s - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0078 - val_accuracy: 0.9972 - 644ms/epoch - 1ms/step\n",
      "Epoch 14/30\n",
      "540/540 - 1s - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0114 - val_accuracy: 0.9953 - 614ms/epoch - 1ms/step\n",
      "Epoch 15/30\n",
      "540/540 - 1s - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0124 - val_accuracy: 0.9955 - 676ms/epoch - 1ms/step\n",
      "Epoch 16/30\n",
      "540/540 - 1s - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0155 - val_accuracy: 0.9942 - 607ms/epoch - 1ms/step\n",
      "Epoch 17/30\n",
      "540/540 - 1s - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0086 - val_accuracy: 0.9973 - 645ms/epoch - 1ms/step\n",
      "Epoch 18/30\n",
      "540/540 - 1s - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0061 - val_accuracy: 0.9982 - 647ms/epoch - 1ms/step\n",
      "Epoch 19/30\n",
      "540/540 - 1s - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0160 - val_accuracy: 0.9943 - 613ms/epoch - 1ms/step\n",
      "Epoch 20/30\n",
      "540/540 - 1s - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0056 - val_accuracy: 0.9982 - 626ms/epoch - 1ms/step\n",
      "Epoch 21/30\n",
      "540/540 - 1s - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0086 - val_accuracy: 0.9970 - 600ms/epoch - 1ms/step\n",
      "Epoch 22/30\n",
      "540/540 - 1s - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0054 - val_accuracy: 0.9982 - 604ms/epoch - 1ms/step\n",
      "Epoch 23/30\n",
      "540/540 - 1s - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9983 - 615ms/epoch - 1ms/step\n",
      "Epoch 24/30\n",
      "540/540 - 1s - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0100 - val_accuracy: 0.9967 - 634ms/epoch - 1ms/step\n",
      "Epoch 25/30\n",
      "540/540 - 1s - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0068 - val_accuracy: 0.9973 - 609ms/epoch - 1ms/step\n",
      "Epoch 26/30\n",
      "540/540 - 1s - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9985 - 641ms/epoch - 1ms/step\n",
      "Epoch 27/30\n",
      "540/540 - 1s - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0055 - val_accuracy: 0.9982 - 601ms/epoch - 1ms/step\n",
      "Epoch 28/30\n",
      "540/540 - 1s - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0102 - val_accuracy: 0.9963 - 597ms/epoch - 1ms/step\n",
      "Epoch 29/30\n",
      "540/540 - 1s - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0056 - val_accuracy: 0.9982 - 591ms/epoch - 1ms/step\n",
      "Epoch 30/30\n",
      "540/540 - 1s - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0103 - val_accuracy: 0.9962 - 639ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x283b722d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine the maximum number of epochs\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "#fit the model by training data, total number of epochs and the validation data\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs, validation_targets), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12832487",
   "metadata": {},
   "source": [
    "### Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20f75012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1667 - accuracy: 0.9731\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c99020fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.17. Test accuracy: 97.31%\n"
     ]
    }
   ],
   "source": [
    "#apply formatting\n",
    "print(\"Test loss: {0:.2f}. Test accuracy: {1:.2f}%\".format(test_loss, test_accuracy * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37962b",
   "metadata": {},
   "source": [
    "The final test accuracy should be roughly around 97%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
